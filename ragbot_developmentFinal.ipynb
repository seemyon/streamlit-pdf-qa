{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013c9840",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "Set up a clean, reproducible development environment for building a LangChain-based QA app that can:\n",
    "\n",
    "- Read PDF files\n",
    "\n",
    "- Break them into chunks\n",
    "\n",
    "- Create embeddings\n",
    "\n",
    "- Retrieve relevant context using FAISS\n",
    "\n",
    "- Use OpenAI's GPT-4.1  ` to generate answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be925d",
   "metadata": {},
   "source": [
    "## Step 1: Project Set Up\n",
    "\n",
    "### 1.1 Create Your Project Folder and Open It in VS Code\n",
    "Why? Keeping everything in one folder ensures modularity, version control, and easier sharing.\n",
    "\n",
    "- Open your terminal or file explorer\n",
    "\n",
    "- Create the folder - Either create folder using interface/file explorer or programatically as below\n",
    "\n",
    "``mkdir rag_bot``\n",
    "\n",
    "``cd rag_bot``\n",
    "\n",
    "- Open this folder in VS Code (# If you have VSCode CLI setup:)\n",
    "\n",
    "``.code``\n",
    "\n",
    "- or simply open the vscode, and from there open the rag_bot folder you created earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c09bc73",
   "metadata": {},
   "source": [
    "### 1.2: Create a Virtual Python Environment\n",
    "Why? Virtual environments isolate your projectâ€™s dependencies so they donâ€™t interfere with other Python projects on your machine.\n",
    "\n",
    "Windows: \n",
    "\n",
    "``python -m venv rag_bot`\n",
    "\n",
    "``rag_bot_env\\Scripts\\activate``\n",
    "\n",
    "Mac: \n",
    "\n",
    "``python3 -m venv rag_bot``\n",
    "\n",
    "``source rag_bot_env/bin/activate``\n",
    "\n",
    "Once activated, your terminal should show (rag_bot) before the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e872b",
   "metadata": {},
   "source": [
    "### 1.3: Install Required Libraries\n",
    "\n",
    "Install the exact LangChain modules (v0.3+) along with related tools.\n",
    "\n",
    "``pip install python-dotenv langchain-community langchain-openai pypdf faiss-cpu streamlit``\n",
    "\n",
    "and install other required documents as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d285b",
   "metadata": {},
   "source": [
    "### 1.4: Generate requirements.txt\n",
    "\n",
    "Why? Captures your current environment so anyone else can recreate it exactly.\n",
    "\n",
    "``pip freeze > requirements.txt``\n",
    "\n",
    "This command will create new requirements.txt file with the above installed libraries in your current project directory.\n",
    "\n",
    "The alternative way of creating requirements.txt is to - either copy whole requirements.txt from my folder or ,first create this requirements.txt file inside your current project directory and copy and paste above packages and run\n",
    "\n",
    "``pip install -r requirements.txt``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b0683",
   "metadata": {},
   "source": [
    "### 1.5: OPENAI_API_KEY\n",
    "\n",
    "Create a .env file in your project directory with your OpenAI API key:\n",
    "\n",
    "OPENAI_API_KEY=your_openai_api_key_here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5e180d",
   "metadata": {},
   "source": [
    "### Step 2: Import Required Libraries\n",
    "\n",
    "Explanation:\n",
    "These imports bring in necessary modules for loading PDFs, splitting text, creating embeddings, interacting with OpenAI's GPT-4, and constructing the LCEL pipeline."
   ]
  },
  {
   "cell_type": "code",
   "id": "4e57b05f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:03:12.886888Z",
     "start_time": "2025-05-13T20:03:10.561349Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain components\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap, RunnablePassthrough\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "b9f52b28",
   "metadata": {},
   "source": [
    "### Step 3: Load OpenAI API Key\n",
    "Explanation:\n",
    "This step securely loads your OpenAI API key from the .env file, avoiding hardcoding sensitive information."
   ]
  },
  {
   "cell_type": "code",
   "id": "f3f7762d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:03:14.745919Z",
     "start_time": "2025-05-13T20:03:14.740797Z"
    }
   },
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "81671a82",
   "metadata": {},
   "source": [
    "### Step 4: Load and Preview PDF Document\n",
    "\n",
    "Explanation:\n",
    "This step uses PyPDFLoader to read the PDF and loads each page as a separate document, allowing for easier processing."
   ]
  },
  {
   "cell_type": "code",
   "id": "5e56d881",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:03:46.522197Z",
     "start_time": "2025-05-13T20:03:46.320630Z"
    }
   },
   "source": [
    "# Specify the path to your PDF file\n",
    "data = r\"C:\\Users\\u116503.GLOBAL\\OneDrive - Bio-Rad Laboratories Inc\\Documents\\PycharmProjects\\streamlit-pdf-qa-main\\data\" #Replace with your actual data path\n",
    "pdf_path = data+\"/\"+\"IntroToUSEconomyHousingMarket.pdf\"  # Replace with your actual PDF file\n",
    "\n",
    "# Load the PDF\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Preview the number of pages and content of the first page\n",
    "print(f\"âœ… Loaded {len(documents)} pages from the PDF.\")\n",
    "print(f\"\\nðŸ”¹ Sample Page Content:\\n{documents[0].page_content[:500]}...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 3 pages from the PDF.\n",
      "\n",
      "ðŸ”¹ Sample Page Content:\n",
      "https://crsreports.congress.gov \n",
      " \n",
      "Updated January 3, 2023\n",
      "Introduction to U.S. Economy: Housing Market\n",
      "The Housing Market  \n",
      "Real estate and the housing market play an important role in \n",
      "the U.S. economy. At the individual level, roughly 65% of \n",
      "occupied housing units are owner occupied, homes are \n",
      "often a substantial source of household wealth in the United \n",
      "States, and housing construction provides widespread \n",
      "employment. At the aggregate level, housing accounts for a \n",
      "significant portion of a...\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "1597d616",
   "metadata": {},
   "source": [
    "###  Step 5: Split Document into Chunks\n",
    "\n",
    "Explanation:\n",
    "Splitting the document into chunks ensures that each piece of text is within the token limit of the language model and maintains context through overlapping."
   ]
  },
  {
   "cell_type": "code",
   "id": "e4595eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:06:02.888556Z",
     "start_time": "2025-05-13T20:06:02.879585Z"
    }
   },
   "source": [
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,     # Maximum number of characters per chunk\n",
    "    chunk_overlap=200    # Overlap between chunks to maintain context\n",
    ")\n",
    "\n",
    "# Split the documents into chunks\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Preview the number of chunks and content of the first chunk\n",
    "print(f\"\\nâœ… Created {len(splits)} text chunks.\")\n",
    "print(f\"\\nðŸ”¹ Sample Chunk:\\n{splits[0].page_content[:500]}...\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Created 13 text chunks.\n",
      "\n",
      "ðŸ”¹ Sample Chunk:\n",
      "https://crsreports.congress.gov \n",
      " \n",
      "Updated January 3, 2023\n",
      "Introduction to U.S. Economy: Housing Market\n",
      "The Housing Market  \n",
      "Real estate and the housing market play an important role in \n",
      "the U.S. economy. At the individual level, roughly 65% of \n",
      "occupied housing units are owner occupied, homes are \n",
      "often a substantial source of household wealth in the United \n",
      "States, and housing construction provides widespread \n",
      "employment. At the aggregate level, housing accounts for a \n",
      "significant portion of a...\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "ce91e818",
   "metadata": {},
   "source": [
    "### Step 6: Create Vector Store with OpenAI Embeddings\n",
    "Explanation:\n",
    "This step converts text chunks into vector embeddings using OpenAI's model and stores them in a FAISS vector store for efficient similarity search.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d83da92e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:06:08.201377Z",
     "start_time": "2025-05-13T20:06:05.325062Z"
    }
   },
   "source": [
    "# Initialize OpenAI embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Create a FAISS vector store from the document chunks\n",
    "vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "# Create a retriever to fetch relevant documents\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})  # Retrieves top 3 relevant chunks\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "3e458a97",
   "metadata": {},
   "source": [
    "### Step 7: Define Prompt Template\n",
    "Explanation:\n",
    "The prompt guides GPT-4 to use the provided context to answer the question and to acknowledge when the answer isn't present in the context."
   ]
  },
  {
   "cell_type": "code",
   "id": "a5347251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:06:10.817784Z",
     "start_time": "2025-05-13T20:06:10.813634Z"
    }
   },
   "source": [
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "You are a helpful assistant. Use the following context to answer the user's question.\n",
    "If the answer is not in the context, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "bd6a2d70",
   "metadata": {},
   "source": [
    "### Step 8: Create the LCEL Chain\n",
    "Explanation:\n",
    "This pipeline first retrieves relevant context, then formats it with the question using the prompt, and finally generates an answer using GPT-4.1."
   ]
  },
  {
   "cell_type": "code",
   "id": "06af1045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:06:13.614602Z",
     "start_time": "2025-05-13T20:06:12.763154Z"
    }
   },
   "source": [
    "# Initialize the ChatOpenAI model\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\")\n",
    "\n",
    "# Construct the LCEL pipeline\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "d9252147",
   "metadata": {},
   "source": [
    "### Step 9: Ask a Question and Get an Answer\n",
    "Explanation:\n",
    "This step sends the user's question through the pipeline and prints out the model's response."
   ]
  },
  {
   "cell_type": "code",
   "id": "519b531a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:06:18.989168Z",
     "start_time": "2025-05-13T20:06:15.031716Z"
    }
   },
   "source": [
    "# Define your question\n",
    "question = \"What is the main topic of this document?\"\n",
    "\n",
    "# Invoke the pipeline with the question\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "# Display the answer\n",
    "print(\"\\nðŸ’¬ GPT-4's Answer:\")\n",
    "print(response.content)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¬ GPT-4's Answer:\n",
      "The main topic of this document is an introduction to the U.S. economy with a focus on the housing market, including its role in individual wealth, employment, and its broader effects on economic activity.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "e2653760",
   "metadata": {},
   "source": [
    "### Step 10: Display Retrieved Source Chunks\n",
    "\n",
    "Explanation:\n",
    "This step shows the specific chunks of the document that were retrieved to answer the question, including page numbers and text snippets, providing transparency and traceability."
   ]
  },
  {
   "cell_type": "code",
   "id": "bf3f1ddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:06:22.529110Z",
     "start_time": "2025-05-13T20:06:21.693415Z"
    }
   },
   "source": [
    "# Retrieve the source documents used to answer the question\n",
    "retrieved_docs = retriever.invoke(question)\n",
    "\n",
    "# Display the sources\n",
    "print(\"\\nðŸ“š Sources Used:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    page = doc.metadata.get(\"page\", \"N/A\")\n",
    "    snippet = doc.page_content[:300].replace(\"\\n\", \" \") + \"...\"\n",
    "    print(f\"\\n Source #{i}\")\n",
    "    print(f\" Page: {page}\")\n",
    "    print(f\" Text Snippet:\\n{snippet}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“š Sources Used:\n",
      "\n",
      " Source #1\n",
      " Page: 2\n",
      " Text Snippet:\n",
      "Introduction to U.S. Economy: Housing Market  https://crsreports.congress.gov | IF11327 Â· VERSION 10 Â· UPDATED    Lida R. Weinstock, Analyst Macroeconomic Policy    IF11327     Disclaimer  This document was prepared by the Congressional Research Service (CRS). CRS serves as nonpartisan shared staff ...\n",
      "\n",
      " Source #2\n",
      " Page: 2\n",
      " Text Snippet:\n",
      "reproduced and distributed in its entirety without permission from CRS. However, as a CRS Report may include  copyrighted images or material from a third party, you may need to obtain the permissio n of the copyright holder if you  wish to copy or otherwise use copyrighted material....\n",
      "\n",
      " Source #3\n",
      " Page: 0\n",
      " Text Snippet:\n",
      "https://crsreports.congress.gov    Updated January 3, 2023 Introduction to U.S. Economy: Housing Market The Housing Market   Real estate and the housing market play an important role in  the U.S. economy. At the individual level, roughly 65% of  occupied housing units are owner occupied, homes are  ...\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "b8e0a43a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T20:06:27.948370Z",
     "start_time": "2025-05-13T20:06:25.458934Z"
    }
   },
   "source": [
    "# Define your question\n",
    "question = \"Where is the university of Georgia?\"\n",
    "\n",
    "# Invoke the pipeline with the question\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "# Display the answer\n",
    "print(\"\\nðŸ’¬ GPT-4's Answer:\")\n",
    "print(response.content)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¬ GPT-4's Answer:\n",
      "I don't know.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "61548aaa",
   "metadata": {},
   "source": [
    "### Note:\n",
    "GPT-4 uses all 3 retrieved sources as context â€” not just the first one.\n",
    "Here's what happens:\n",
    "\n",
    "- Retriever Stage:\n",
    "\n",
    "``retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3})``\n",
    "\n",
    "This retrieves the top 3 most relevant chunks (based on vector similarity to the question).\n",
    "\n",
    "- Prompt Stage:\n",
    "\n",
    "The text of all 3 chunks is concatenated into a single string under the {context} variable in the prompt template:\n",
    "\n",
    "- LLM Stage:\n",
    "\n",
    "GPT-4 receives that full prompt and is free to use any or all of those 3 chunks to generate the final answer.\n",
    "\n",
    "It may summarize, rephrase, or even synthesize across the chunks depending on the content and quality of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6089c9ae",
   "metadata": {},
   "source": [
    "### Thank You - Next Step\n",
    "- Convert this to deploybale modular code\n",
    "- create streamlit application\n",
    "- deploy it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
